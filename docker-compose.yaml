services:
  postgres:
    image: postgres:18-alpine
    container_name: distributed-data-storage-db
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./scripts/db/:/docker-entrypoint-initdb.d
    ports:
      - "${POSTGRES_EXTERNAL_PORT}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 3s
      timeout: 3s
      retries: 5
    networks:
      - spark_network

  # Spark Master (координатор)
  spark-master:
    build:
      context: ./spark/
      dockerfile: Dockerfile
      args:
        POSTGRES_JDBC_VERSION: ${POSTGRES_JDBC_VERSION}
    container_name: distributed-data-storage-spark_master
    restart: unless-stopped
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --host spark-master --port ${SPARK_MASTER_PORT} --webui-port ${SPARK_MASTER_WEBUI_PORT}
    environment:
      SPARK_MASTER_HOST: spark-master
      SPARK_MASTER_PORT: ${SPARK_MASTER_PORT}
      SPARK_MASTER_WEBUI_PORT: ${SPARK_MASTER_WEBUI_PORT}

      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}

      POSTGRES_JDBC_VERSION: ${POSTGRES_JDBC_VERSION}
      KAFKA_TOPIC_NAME: ${KAFKA_TOPIC_NAME}
    ports:
      - "${SPARK_MASTER_WEBUI_PORT}:8082"
      - "${SPARK_MASTER_PORT}:7077"
    volumes:
      - ./scripts/spark_python:/opt/spark/scripts
    networks:
      - spark_network
    depends_on:
      postgres:
        condition: service_healthy

  # Spark Worker (исполнитель задач)
  spark-worker:
    build:
      context: ./spark/
      dockerfile: Dockerfile
      args:
        POSTGRES_JDBC_VERSION: ${POSTGRES_JDBC_VERSION}
    container_name: distributed-data-storage-spark_worker_1
    restart: unless-stopped
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:${SPARK_MASTER_PORT}
    environment:
      SPARK_MASTER_URL: spark://spark-master:${SPARK_MASTER_PORT}
      SPARK_WORKER_CORES: ${SPARK_WORKER_CORES}
      SPARK_WORKER_MEMORY: ${SPARK_WORKER_MEMORY}

      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}

      POSTGRES_JDBC_VERSION: ${POSTGRES_JDBC_VERSION}
      KAFKA_TOPIC_NAME: ${KAFKA_TOPIC_NAME}
    ports:
      - "${SPARK_WORKER_WEBUI_PORT}:8081"
    volumes:
      - ./scripts/spark_python:/opt/spark/scripts
    networks:
      - spark_network
    depends_on:
      - spark-master

  # Spark Driver (координатор)
  spark-consumer:
    build:
      context: ./spark/
      dockerfile: Dockerfile
      args:
        POSTGRES_JDBC_VERSION: ${POSTGRES_JDBC_VERSION}
    container_name: distributed-data-storage-spark_consumer
    command: >
      /opt/spark/bin/spark-submit --master spark://spark-master:${SPARK_MASTER_PORT} /opt/spark/scripts/kafka_to_postgres.py
    environment:
      SPARK_MASTER_PORT: ${SPARK_MASTER_PORT}

      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}

      POSTGRES_JDBC_VERSION: ${POSTGRES_JDBC_VERSION}
      KAFKA_TOPIC_NAME: ${KAFKA_TOPIC_NAME}
    ports:
      - "4040:4040"
    volumes:
      - ./scripts/spark_python:/opt/spark/scripts
      - spark_checkpoint:/opt/spark/checkpoints
    depends_on:
      kafka:
        condition: service_healthy
      spark-master:
        condition: service_started
    networks:
      - spark_network

  kafka:
    image: apache/kafka:latest
    container_name: distributed-data-storage-kafka
    ports:
      - "29092:29092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller

      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:29092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT

      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3

    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - spark_network
    healthcheck:
      test:
        [
          "CMD",
          "bash",
          "-c",
          "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list > /dev/null 2>&1",
        ]
      interval: 3s
      timeout: 3s
      retries: 5

  producer:
    container_name: distributed-data-storage-producer
    build:
      context: .
      dockerfile: ./producer/Dockerfile
    volumes:
      - ./producer/state:/app/state
    environment:
      PRODUCER_INTERVAL_SEC: ${PRODUCER_INTERVAL_SEC}
      PRODUCER_STATE_FILE: ${PRODUCER_STATE_FILE}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_TOPIC_NAME: ${KAFKA_TOPIC_NAME}
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - spark_network

  logs_sender:
    container_name: distributed-data-storage-logs_sender
    build:
      context: .
      dockerfile: ./logs_sender/Dockerfile
    environment:
      LOGS_SENDER_BATCH_SIZE: ${LOGS_SENDER_BATCH_SIZE}
      LOGS_SENDER_INTERVAL_SEC: ${LOGS_SENDER_INTERVAL_SEC}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - spark_network

  kafka-ui:
    image: ghcr.io/kafbat/kafka-ui
    container_name: distributed-data-storage-kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: ${KAFKA_UI_CLUSTER_NAME}
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: PLAINTEXT
    networks:
      - spark_network
    volumes:
      - kafka_ui_data:/etc/kafkaui

networks:
  spark_network:
    driver: bridge

volumes:
  pg_data:
  iceberg_pg_data:
  kafka_data:
  kafka_ui_data:
  spark_checkpoint:
